# -*- coding: utf-8 -*-
"""
WAWATUBE-DEMO : Faceless Video Content Generator
‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏°‡∏∑‡∏≠‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ñ‡∏≠‡∏ô‡πÄ‡∏ó‡∏ô‡∏ï‡πå‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠‡∏Ñ‡∏£‡∏ö‡∏ß‡∏á‡∏à‡∏£ ‡∏ï‡∏±‡πâ‡∏á‡πÅ‡∏ï‡πà‡∏Ñ‡∏¥‡∏î‡πÑ‡∏≠‡πÄ‡∏î‡∏µ‡∏¢ ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡∏™‡∏Ñ‡∏£‡∏¥‡∏õ‡∏ï‡πå ‡∏à‡∏ô‡∏ñ‡∏∂‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏û‡∏≤‡∏Å‡∏¢‡πå
- ‡πÉ‡∏ä‡πâ OpenAI (GPT-4o) ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏≠‡πÄ‡∏î‡∏µ‡∏¢‡πÅ‡∏•‡∏∞‡∏™‡∏Ñ‡∏£‡∏¥‡∏õ‡∏ï‡πå
- ‡πÉ‡∏ä‡πâ Google Cloud Text-to-Speech ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏û‡∏≤‡∏Å‡∏¢‡πå
"""

# --- 1. IMPORTS ---
import os
import re
import io
import streamlit as st
import openai
from dotenv import load_dotenv
from google.cloud import texttospeech
from pydub import AudioSegment
# ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÉ‡∏´‡πâ‡πÅ‡∏ô‡πà‡πÉ‡∏à‡∏ß‡πà‡∏≤ final_video_generator.py ‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô directory ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô‡∏Å‡∏±‡∏ö app.py ‡∏´‡∏£‡∏∑‡∏≠‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô path ‡∏ó‡∏µ‡πà Python ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ import ‡πÑ‡∏î‡πâ
from final_video_generator import generate_final_video
# ‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏´‡∏ï‡∏∏: ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ pydub ‡∏Ñ‡∏∏‡∏ì‡∏≠‡∏≤‡∏à‡∏ï‡πâ‡∏≠‡∏á‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á ffmpeg ‡πÉ‡∏ô‡∏£‡∏∞‡∏ö‡∏ö‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì‡∏î‡πâ‡∏ß‡∏¢
# 1. pip install pydub
# 2. ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á ffmpeg (‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Windows: https://www.gyan.dev/ffmpeg/builds/)

st.set_page_config(page_title="WAWATUBE-DEMO - Video Content Generator", layout="wide")
# --- 2. CONSTANTS ---
VOICE_LIST = [
    # ‡∏ä‡∏≤‡∏¢ (MALE)
    ("‡∏ä‡∏≤‡∏¢ 1 (Achird, ‡∏ü‡∏±‡∏á‡∏™‡∏ö‡∏≤‡∏¢/‡∏™‡∏∏‡∏†‡∏≤‡∏û)", "th-TH-Chirp3-HD-Achird"),
    ("‡∏ä‡∏≤‡∏¢ 2 (Fenrir, ‡∏à‡∏£‡∏¥‡∏á‡∏à‡∏±‡∏á/‡πÄ‡∏Ç‡πâ‡∏°‡πÅ‡∏Ç‡πá‡∏á)", "th-TH-Chirp3-HD-Fenrir"),
    ("‡∏ä‡∏≤‡∏¢ 3 (Orus, ‡πÇ‡∏°‡πÄ‡∏î‡∏¥‡∏£‡πå‡∏ô/‡∏Å‡∏£‡∏∞‡∏â‡∏±‡∏ö‡∏Å‡∏£‡∏∞‡πÄ‡∏â‡∏á)", "th-TH-Chirp3-HD-Orus"),
    ("‡∏ä‡∏≤‡∏¢ 4 (Zubenelgenubi, ‡∏ô‡∏∏‡πà‡∏°‡∏•‡∏∂‡∏Å/‡∏≠‡∏ö‡∏≠‡∏∏‡πà‡∏ô)", "th-TH-Chirp3-HD-Zubenelgenubi"),
    ("‡∏ä‡∏≤‡∏¢ 5 (Umbriel, ‡∏°‡∏±‡πà‡∏ô‡πÉ‡∏à/‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏´‡∏ô‡∏∏‡πà‡∏°)", "th-TH-Chirp3-HD-Umbriel"),

    # ‡∏´‡∏ç‡∏¥‡∏á (FEMALE)
    ("‡∏´‡∏ç‡∏¥‡∏á 1 (Achernar, ‡∏ü‡∏±‡∏á‡∏á‡πà‡∏≤‡∏¢/‡πÄ‡∏õ‡πá‡∏ô‡∏ò‡∏£‡∏£‡∏°‡∏ä‡∏≤‡∏ï‡∏¥)", "th-TH-Chirp3-HD-Achernar"),
    ("‡∏´‡∏ç‡∏¥‡∏á 2 (Laomedeia, ‡∏≠‡πà‡∏≠‡∏ô‡πÇ‡∏¢‡∏ô/‡∏≠‡∏ö‡∏≠‡∏∏‡πà‡∏ô)", "th-TH-Chirp3-HD-Laomedeia"),
    ("‡∏´‡∏ç‡∏¥‡∏á 3 (Leda, ‡∏´‡∏ß‡∏≤‡∏ô/‡∏ô‡∏∏‡πà‡∏°‡∏ô‡∏ß‡∏•)", "th-TH-Chirp3-HD-Leda"),
    ("‡∏´‡∏ç‡∏¥‡∏á 4 (Vindemiatrix, ‡∏™‡∏∏‡∏†‡∏≤‡∏û/‡πÄ‡∏õ‡πá‡∏ô‡∏ó‡∏≤‡∏á‡∏Å‡∏≤‡∏£)", "th-TH-Chirp3-HD-Vindemiatrix"),
    ("‡∏´‡∏ç‡∏¥‡∏á 5 (Zephyr, ‡∏™‡∏î‡πÉ‡∏™/‡∏Å‡∏£‡∏∞‡∏â‡∏±‡∏ö‡∏Å‡∏£‡∏∞‡πÄ‡∏â‡∏á)", "th-TH-Chirp3-HD-Zephyr"),
]

# --- 2.1. VOICE STYLE MAP ---
VOICE_STYLE_MAP = {
    "‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏ú‡∏µ‡πÑ‡∏ó‡∏¢ & ‡∏ï‡∏≥‡∏ô‡∏≤‡∏ô‡∏•‡∏µ‡πâ‡∏•‡∏±‡∏ö": "‡∏•‡∏∂‡∏Å‡∏•‡∏±‡∏ö/‡∏à‡∏£‡∏¥‡∏á‡∏à‡∏±‡∏á",
    "‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå": "‡∏à‡∏£‡∏¥‡∏á‡∏à‡∏±‡∏á/‡πÄ‡∏õ‡πá‡∏ô‡∏ó‡∏≤‡∏á‡∏Å‡∏≤‡∏£",
    "‡∏ß‡∏¥‡∏ó‡∏¢‡∏≤‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå‡∏£‡∏≠‡∏ö‡∏ï‡∏±‡∏ß": "‡∏â‡∏•‡∏≤‡∏î/‡∏™‡∏î‡πÉ‡∏™",
    "‡∏Å‡∏≤‡∏£‡∏û‡∏±‡∏í‡∏ô‡∏≤‡∏ï‡∏ô‡πÄ‡∏≠‡∏á": "‡πÉ‡∏´‡πâ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÉ‡∏à/‡∏≠‡∏ö‡∏≠‡∏∏‡πà‡∏ô",
    "‡πÄ‡∏ó‡∏Ñ‡πÇ‡∏ô‡πÇ‡∏•‡∏¢‡∏µ AI": "‡πÇ‡∏°‡πÄ‡∏î‡∏¥‡∏£‡πå‡∏ô/‡∏Å‡∏£‡∏∞‡∏â‡∏±‡∏ö‡∏Å‡∏£‡∏∞‡πÄ‡∏â‡∏á",
    "‡∏Å‡∏≤‡∏£‡πÄ‡∏á‡∏¥‡∏ô-‡∏Å‡∏≤‡∏£‡∏•‡∏á‡∏ó‡∏∏‡∏ô": "‡∏à‡∏£‡∏¥‡∏á‡∏à‡∏±‡∏á",
    "‡∏™‡∏∏‡∏Ç‡∏†‡∏≤‡∏û & ‡πÑ‡∏•‡∏ü‡πå‡∏™‡πÑ‡∏ï‡∏•‡πå": "‡∏≠‡πà‡∏≠‡∏ô‡πÇ‡∏¢‡∏ô/‡∏≠‡∏ö‡∏≠‡∏∏‡πà‡∏ô",
    "‡∏ó‡πà‡∏≠‡∏á‡πÄ‡∏ó‡∏µ‡πà‡∏¢‡∏ß & ‡∏õ‡∏£‡∏∞‡∏™‡∏ö‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏ä‡∏µ‡∏ß‡∏¥‡∏ï": "‡∏™‡∏î‡πÉ‡∏™/‡πÄ‡∏•‡πà‡∏≤‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á",
    "‡∏ö‡∏±‡∏ô‡πÄ‡∏ó‡∏¥‡∏á-‡∏ã‡∏µ‡∏£‡∏µ‡∏™‡πå/‡∏î‡∏≤‡∏£‡∏≤": "‡∏™‡∏ô‡∏∏‡∏Å/‡∏ö‡∏±‡∏ô‡πÄ‡∏ó‡∏¥‡∏á",
    "‡∏Ç‡πà‡∏≤‡∏ß/‡πÇ‡∏ã‡πÄ‡∏ä‡∏µ‡∏¢‡∏•/‡πÄ‡∏ó‡∏£‡∏ô‡∏î‡πå‡∏Æ‡∏¥‡∏ï": "‡∏Å‡∏£‡∏∞‡∏ä‡∏±‡∏ö/‡πÄ‡∏Ç‡πâ‡∏°‡∏Ç‡πâ‡∏ô",
    "How-To / ‡πÄ‡∏Ñ‡∏•‡πá‡∏î‡∏•‡∏±‡∏ö / DIY": "‡∏™‡∏≠‡∏ô/‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏á‡πà‡∏≤‡∏¢",
    "‡∏ò‡∏£‡∏£‡∏°‡∏ä‡∏≤‡∏ï‡∏¥/‡∏™‡∏±‡∏ï‡∏ß‡πå‡πÇ‡∏•‡∏Å": "‡∏ú‡πà‡∏≠‡∏ô‡∏Ñ‡∏•‡∏≤‡∏¢/‡∏≠‡∏ö‡∏≠‡∏∏‡πà‡∏ô"
}
def get_voice_style_by_topic(topic):
    return VOICE_STYLE_MAP.get(topic, "‡∏õ‡∏Å‡∏ï‡∏¥")

# --- 3. CLIENT INITIALIZATION ---
def initialize_clients():
    """
    ‡πÇ‡∏´‡∏•‡∏î‡∏Ñ‡πà‡∏≤‡∏à‡∏≤‡∏Å .env ‡πÅ‡∏•‡∏∞‡∏™‡∏£‡πâ‡∏≤‡∏á client ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö OpenAI ‡πÅ‡∏•‡∏∞ Google Cloud TTS
    ‡∏Ñ‡∏∑‡∏ô‡∏Ñ‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô (openai_client, gcp_tts_client)
    """
    load_dotenv()

    openai_client = None
    gcp_tts_client = None

    # ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ OpenAI Client
    try:
        api_key = os.getenv("OPENAI_API_KEY")
        if not api_key:
            raise ValueError("OPENAI_API_KEY is not set in .env file.")
        openai_client = openai.OpenAI(api_key=api_key)
        st.session_state.openai_client = openai_client # Store in session state
    except ValueError as e:
        st.error(f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ OpenAI: {e}")
    except Exception as e:
        st.error(f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏Ñ‡∏≤‡∏î‡∏Ñ‡∏¥‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ OpenAI: {e}")

    # ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ Google Cloud TTS Client
    try:
        credentials_path = "teptubev1-52050d27583e.json"
        if not os.path.exists(credentials_path):
             raise FileNotFoundError(f"‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå credentials \'{credentials_path}\'")
        os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = credentials_path
        gcp_tts_client = texttospeech.TextToSpeechClient()
        st.session_state.gcp_tts_client = gcp_tts_client # Store in session state
    except FileNotFoundError as e:
        st.error(f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ Google Cloud TTS: {e}")
    except Exception as e:
        st.error(f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏Ñ‡∏≤‡∏î‡∏Ñ‡∏¥‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ Google Cloud TTS: {e}")

    return openai_client, gcp_tts_client


# --- 4. HELPER FUNCTIONS (Text Processing) ---
def clean_script_for_tts(text):
    """‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡∏™‡∏Ñ‡∏£‡∏¥‡∏õ‡∏ï‡πå‡∏Å‡πà‡∏≠‡∏ô‡∏™‡πà‡∏á‡πÑ‡∏õ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏™‡∏µ‡∏¢‡∏á (‡πÄ‡∏ß‡∏≠‡∏£‡πå‡∏ä‡∏±‡∏ô‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á)"""
    text = re.sub(r'\[.*?\]', '', text)
    text = re.sub(r"^(‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏ö‡∏£‡∏£‡∏¢‡∏≤‡∏¢:|‡πÄ‡∏õ‡∏¥‡∏î‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á:)\s*", "", text, flags=re.MULTILINE)
    return text.strip()

def split_text_for_tts(text, max_sentence_len=25):
    import re
    # ‡∏ï‡∏±‡∏î‡∏î‡πâ‡∏ß‡∏¢ . ! ? ‡∏´‡∏£‡∏∑‡∏≠ ‡∏Ç‡∏∂‡πâ‡∏ô‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡πÉ‡∏´‡∏°‡πà
    sentences = re.split(r'([.!?]|[\n])', text)
    sentences = [
        (sentences[i] + sentences[i+1]).strip()
        for i in range(0, len(sentences)-1, 2)
    ]
    results = []
    for s in sentences:
        if len(s.split()) > max_sentence_len:
            chunks = re.split(r'(,|;|‡πÅ‡∏•‡∏∞|‡πÅ‡∏ï‡πà)', s)
            part = ''
            for c in chunks:
                if len((part + c).split()) > max_sentence_len:
                    results.append(part.strip())
                    part = c
                else:
                    part += c
            if part.strip():
                results.append(part.strip())
        else:
            results.append(s)
    return [x for x in results if x.strip()]

def split_script_for_image(script_text):
    # ‡πÅ‡∏ö‡πà‡∏á‡∏™‡∏Ñ‡∏£‡∏¥‡∏õ‡∏ï‡πå‡∏ï‡∏≤‡∏° '‡∏¢‡πà‡∏≠‡∏´‡∏ô‡πâ‡∏≤' (‡πÅ‡∏¢‡∏Å‡∏ó‡∏µ‡πà‡∏°‡∏µ‡πÄ‡∏ß‡πâ‡∏ô‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡πÄ‡∏õ‡∏•‡πà‡∏≤)
    import re
    paras = re.split(r'\n\s*\n', script_text.strip())
    # ‡∏•‡∏ö‡∏ä‡πà‡∏≠‡∏á‡∏ß‡πà‡∏≤‡∏á, ‡∏•‡∏ö‡∏¢‡πà‡∏≠‡∏´‡∏ô‡πâ‡∏≤‡∏ß‡πà‡∏≤‡∏á
    return [p.strip() for p in paras if p.strip()]

# --- 5. API FUNCTIONS (Interacting with OpenAI) ---
def gen_idea_list(client, topic):
    """‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡πÑ‡∏≠‡πÄ‡∏î‡∏µ‡∏¢‡∏à‡∏≤‡∏Å OpenAI (‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á Prompt ‡πÉ‡∏´‡πâ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ä‡∏∑‡πà‡∏≠‡∏Ñ‡∏•‡∏¥‡∏õ‡∏ó‡∏µ‡πà‡∏ô‡πà‡∏≤‡∏™‡∏ô‡πÉ‡∏à)"""
    prompt = (
        f"‡πÉ‡∏ô‡∏ê‡∏≤‡∏ô‡∏∞‡∏ô‡∏±‡∏Å‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ñ‡∏≠‡∏ô‡πÄ‡∏ó‡∏ô‡∏ï‡πå‡πÑ‡∏ß‡∏£‡∏±‡∏•, ‡∏à‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á \"‡∏ä‡∏∑‡πà‡∏≠‡∏Ñ‡∏•‡∏¥‡∏õ\" ‡∏ó‡∏µ‡πà‡∏™‡∏±‡πâ‡∏ô‡πÅ‡∏•‡∏∞‡∏ô‡πà‡∏≤‡∏™‡∏ô‡πÉ‡∏à‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Youtube/Tiktok ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô 5 ‡∏Ç‡πâ‡∏≠ ‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠: '{topic}'\n\n"
        "‡∏Å‡∏é‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏õ‡∏è‡∏¥‡∏ö‡∏±‡∏ï‡∏¥‡∏ï‡∏≤‡∏°:\n"
        "1. **‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏ä‡∏∑‡πà‡∏≠‡∏Ñ‡∏•‡∏¥‡∏õ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô:** ‡∏´‡πâ‡∏≤‡∏°‡∏°‡∏µ‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏´‡∏£‡∏∑‡∏≠‡∏Ñ‡∏≥‡∏ß‡πà‡∏≤ '‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö...'\n"
        "2. **‡∏™‡∏±‡πâ‡∏ô‡πÅ‡∏•‡∏∞‡∏Å‡∏£‡∏∞‡∏ï‡∏∏‡πâ‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏á‡∏™‡∏±‡∏¢:** ‡πÑ‡∏°‡πà‡πÄ‡∏Å‡∏¥‡∏ô 15 ‡∏Ñ‡∏≥ ‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡∏Ñ‡∏ô‡πÄ‡∏´‡πá‡∏ô‡πÅ‡∏•‡πâ‡∏ß‡∏ï‡πâ‡∏≠‡∏á‡∏≠‡∏¢‡∏≤‡∏Å‡∏£‡∏π‡πâ‡∏ï‡πà‡∏≠‡∏ó‡∏±‡∏ô‡∏ó‡∏µ\n"
        "3. **‡πÉ‡∏ä‡πâ‡∏†‡∏≤‡∏©‡∏≤‡∏ó‡∏µ‡πà‡∏ô‡πà‡∏≤‡∏î‡∏∂‡∏á‡∏î‡∏π‡∏î:** ‡πÄ‡∏ä‡πà‡∏ô '‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏£‡∏¥‡∏á‡∏Ç‡∏≠‡∏á...', '‡∏™‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÉ‡∏Ñ‡∏£‡πÄ‡∏Ñ‡∏¢‡∏ö‡∏≠‡∏Å‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö...', '‡∏ó‡∏≥‡πÑ‡∏°...‡∏ñ‡∏∂‡∏á‡∏ú‡∏¥‡∏î'\n"
        "4. **‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡πÄ‡∏õ‡πá‡∏ô‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏•‡∏Ç‡∏Å‡∏≥‡∏Å‡∏±‡∏ö‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô** (‡πÄ‡∏ä‡πà‡∏ô 1. ‡∏ä‡∏∑‡πà‡∏≠‡∏Ñ‡∏•‡∏¥‡∏õ 2. ‡∏ä‡∏∑‡πà‡∏≠‡∏Ñ‡∏•‡∏¥‡∏õ ...)"
    )
    try:
        response = client.chat.completions.create(
            model="gpt-4o",
            messages=[{"role": "user", "content": prompt}],
            max_tokens=800,
            temperature=0.85,
        )
        ideas_text = response.choices[0].message.content.strip()
        ideas = re.findall(r'^\d+\.\s*(.*)', ideas_text, re.MULTILINE)
        if not ideas:
            ideas = re.findall(r'^\s*-\s*(.*)', ideas_text, re.MULTILINE)
        return [idea.strip().strip('"\'') for idea in ideas if idea.strip()]
    except Exception as e:
        st.error(f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏≠‡πÄ‡∏î‡∏µ‡∏¢: {e}")
        return []

def gen_script(client, topic, idea, length):
    """‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏™‡∏Ñ‡∏£‡∏¥‡∏õ‡∏ï‡πå‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠‡∏à‡∏≤‡∏Å OpenAI (‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á Hook ‡πÉ‡∏´‡πâ‡∏ó‡∏£‡∏á‡∏û‡∏•‡∏±‡∏á‡∏Ç‡∏∂‡πâ‡∏ô)"""
    prompt = (
        f"‡πÉ‡∏ô‡∏ê‡∏≤‡∏ô‡∏∞‡∏ô‡∏±‡∏Å‡πÄ‡∏•‡πà‡∏≤‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡πÅ‡∏ô‡∏ß‡∏•‡∏∂‡∏Å‡∏•‡∏±‡∏ö‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Youtube/Tiktok, ‡∏à‡∏á‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡∏™‡∏Ñ‡∏£‡∏¥‡∏õ‡∏ï‡πå‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß‡∏õ‡∏£‡∏∞‡∏°‡∏≤‡∏ì {length} ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ\n"
        f"‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠‡∏´‡∏•‡∏±‡∏Å: {topic}\n"
        f"‡∏ä‡∏∑‡πà‡∏≠‡∏Ñ‡∏•‡∏¥‡∏õ (‡∏™‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏•‡πà‡∏≤): {idea}\n\n"
        "‡∏Å‡∏é‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏õ‡∏è‡∏¥‡∏ö‡∏±‡∏ï‡∏¥‡∏ï‡∏≤‡∏°‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÄ‡∏Ñ‡∏£‡πà‡∏á‡∏Ñ‡∏£‡∏±‡∏î:\n\n"
        "1. **‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏¥‡∏î‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á (Hook):** ‡∏ï‡πâ‡∏≠‡∏á‡∏Ç‡∏∂‡πâ‡∏ô‡∏ï‡πâ‡∏ô‡∏î‡πâ‡∏ß‡∏¢‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ‡∏ó‡∏µ‡πà‡∏ó‡∏£‡∏á‡∏û‡∏•‡∏±‡∏á ‡∏ô‡πà‡∏≤‡∏ï‡∏Å‡πÉ‡∏à ‡∏´‡∏£‡∏∑‡∏≠‡∏Ç‡∏±‡∏î‡πÅ‡∏¢‡πâ‡∏á‡∏Å‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏ó‡∏±‡∏ô‡∏ó‡∏µ **‡∏´‡πâ‡∏≤‡∏°**‡∏ó‡∏±‡∏Å‡∏ó‡∏≤‡∏¢‡∏´‡∏£‡∏∑‡∏≠‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏ï‡∏±‡∏ß‡πÄ‡∏î‡πá‡∏î‡∏Ç‡∏≤‡∏î (‡πÄ‡∏ä‡πà‡∏ô '‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ‡∏Ñ‡∏£‡∏±‡∏ö', '‡∏ß‡∏±‡∏ô‡∏ô‡∏µ‡πâ‡∏à‡∏∞‡∏°‡∏≤‡πÄ‡∏•‡πà‡∏≤')\n"
        "2. **‡∏†‡∏≤‡∏©‡∏≤:** ‡πÉ‡∏ä‡πâ‡∏†‡∏≤‡∏©‡∏≤‡∏û‡∏π‡∏î‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡∏ò‡∏£‡∏£‡∏°‡∏ä‡∏≤‡∏ï‡∏¥‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡πÄ‡∏•‡πà‡∏≤‡πÉ‡∏´‡πâ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ô‡∏ü‡∏±‡∏á ‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà‡∏†‡∏≤‡∏©‡∏≤‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô\n"
        "3. **‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á:** ‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠ ‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ‡∏™‡∏±‡∏ç‡∏•‡∏±‡∏Å‡∏©‡∏ì‡πå (*, -) ‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ‡∏Ñ‡∏≥‡∏ö‡∏£‡∏£‡∏¢‡∏≤‡∏¢‡πÉ‡∏ô‡∏ß‡∏á‡πÄ‡∏•‡πá‡∏ö (‡πÄ‡∏ä‡πà‡∏ô (‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏î‡∏±‡∏á))\n"
        "4. **‡∏Å‡∏≤‡∏£‡πÅ‡∏ö‡πà‡∏á‡∏¢‡πà‡∏≠‡∏´‡∏ô‡πâ‡∏≤:** ‡∏ô‡∏µ‡πà‡∏Ñ‡∏∑‡∏≠‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î! **‡πÉ‡∏´‡πâ‡πÅ‡∏ö‡πà‡∏á‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡∏¢‡πà‡∏≠‡∏´‡∏ô‡πâ‡∏≤‡∏™‡∏±‡πâ‡∏ô‡πÜ ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô 8-12 ‡∏¢‡πà‡∏≠‡∏´‡∏ô‡πâ‡∏≤** ‡πÇ‡∏î‡∏¢‡πÄ‡∏ß‡πâ‡∏ô‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡∏ß‡πà‡∏≤‡∏á‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏Å‡∏±‡∏ô ‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏¢‡πà‡∏≠‡∏´‡∏ô‡πâ‡∏≤‡∏à‡∏∞‡∏ñ‡∏π‡∏Å‡∏ô‡∏≥‡πÑ‡∏õ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏û 1 ‡∏†‡∏≤‡∏û ‡∏î‡∏±‡∏á‡∏ô‡∏±‡πâ‡∏ô‡∏ï‡πâ‡∏≠‡∏á‡∏™‡∏±‡πâ‡∏ô‡πÅ‡∏•‡∏∞‡∏™‡∏∑‡πà‡∏≠‡∏ñ‡∏∂‡∏á‡∏†‡∏≤‡∏û‡∏ó‡∏µ‡πà‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô\n"
        "5. **‡∏Å‡∏≤‡∏£‡∏õ‡∏¥‡∏î‡∏ó‡πâ‡∏≤‡∏¢:** ‡∏™‡∏£‡∏∏‡∏õ‡πÉ‡∏´‡πâ‡∏Å‡∏£‡∏∞‡∏ä‡∏±‡∏ö‡πÅ‡∏•‡∏∞‡∏ó‡∏¥‡πâ‡∏á‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏õ‡∏•‡∏≤‡∏¢‡πÄ‡∏õ‡∏¥‡∏î‡πÉ‡∏´‡πâ‡∏Ñ‡∏ô‡∏î‡∏π‡πÑ‡∏õ‡∏Ñ‡∏¥‡∏î‡∏ï‡πà‡∏≠\n\n"
        "--- ‡πÄ‡∏£‡∏¥‡πà‡∏°‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡∏™‡∏Ñ‡∏£‡∏¥‡∏õ‡∏ï‡πå‡∏î‡πâ‡∏≤‡∏ô‡∏•‡πà‡∏≤‡∏á‡∏ô‡∏µ‡πâ ---"
    )
    try:
        response = client.chat.completions.create(
            model="gpt-4o",
            messages=[{"role": "user", "content": prompt}],
            max_tokens=1500,
            temperature=0.85,
        )
        return response.choices[0].message.content.strip()
    except Exception as e:
        st.error(f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏™‡∏Ñ‡∏£‡∏¥‡∏õ‡∏ï‡πå: {e}")
        return "‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏™‡∏Ñ‡∏£‡∏¥‡∏õ‡∏ï‡πå"

# --- NEW FUNCTION FOR IMAGE PROMPT GENERATION ---
# (This function seems to be duplicated in final_video_generator, but kept here as it was in the original app.py)
def create_image_prompt_from_thai_text(openai_client, thai_text: str) -> str: # ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô Optional[str] ‡πÄ‡∏õ‡πá‡∏ô str
    """
    ‡∏£‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡∏à‡∏≤‡∏Å‡∏™‡∏Ñ‡∏£‡∏¥‡∏õ‡∏ï‡πå ‡πÅ‡∏•‡πâ‡∏ß‡πÉ‡∏´‡πâ AI ‡∏™‡∏£‡πâ‡∏≤‡∏á prompt ‡∏†‡∏≤‡∏©‡∏≤‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏©‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏†‡∏≤‡∏û
    ‡πÇ‡∏î‡∏¢ AI ‡∏à‡∏∞‡∏ï‡πâ‡∏≠‡∏á‡∏ï‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡πÅ‡∏•‡∏∞‡∏™‡∏£‡πâ‡∏≤‡∏á prompt ‡∏ó‡∏µ‡πà‡∏™‡∏∑‡πà‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏°‡∏≤‡∏¢‡πÅ‡∏•‡∏∞‡πÄ‡∏´‡πá‡∏ô‡∏†‡∏≤‡∏û‡πÑ‡∏î‡πâ‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô
    ‡∏´‡∏≤‡∏Å‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏™‡∏£‡πâ‡∏≤‡∏á prompt ‡πÑ‡∏î‡πâ ‡∏à‡∏∞‡πÉ‡∏ä‡πâ prompt ‡∏™‡∏≥‡∏£‡∏≠‡∏á
    """
    if not thai_text:
        print("Error: No Thai text provided to create image prompt.")
        raise ValueError("No Thai text provided to create image prompt.") 

    prompt_for_ai = (
        f"Consider the following Thai text which describes a scene or concept for a video clip:\n\n"
        f"'{thai_text}'\n\n"
        f"Now, create a creative and visually descriptive English prompt suitable for an AI image generator (like Stable Diffusion). "
        f"The prompt should capture the essence of the Thai text, focusing on visual elements, atmosphere, and key details. "
        f"Do not just translate directly. Imagine the scene and describe it vividly. Aim for around 50-100 words.\n\n"
        f"English Image Prompt:"
    )
    
    try:
        response = openai_client.chat.completions.create(
            model="gpt-4o",
            messages=[{"role": "user", "content": prompt_for_ai}],
            max_tokens=150,
            temperature=0.7,
        )
        image_prompt = response.choices[0].message.content.strip()
        
        if image_prompt and len(image_prompt) > 10:
            return image_prompt
        else:
            print(f"Warning: Generated image prompt was too short or empty for Thai text: '{thai_text[:50]}...'. Using default prompt.")
            return "A generic beautiful scene, art by Studio Ghibli, vibrant colors, detailed illustration" # Default prompt
    except Exception as e:
        print(f"Error creating image prompt from Thai text: {e}. Using default prompt.")
        return "A generic beautiful scene, art by Studio Ghibli, vibrant colors, detailed illustration" # Default prompt

# --- NEW FUNCTION: GENERATE SEO CONTENT ---
def generate_seo_content(client, topic, title, script):
    """
    Generate SEO title, description, and keywords for different platforms.
    """
    prompt = (
        f"‡πÉ‡∏ô‡∏ê‡∏≤‡∏ô‡∏∞‡∏ô‡∏±‡∏Å‡∏Å‡∏≤‡∏£‡∏ï‡∏•‡∏≤‡∏î‡∏Ñ‡∏≠‡∏ô‡πÄ‡∏ó‡∏ô‡∏ï‡πå‡πÅ‡∏•‡∏∞‡∏ú‡∏π‡πâ‡πÄ‡∏ä‡∏µ‡πà‡∏¢‡∏ß‡∏ä‡∏≤‡∏ç‡∏î‡πâ‡∏≤‡∏ô SEO, ‡πÇ‡∏õ‡∏£‡∏î‡∏™‡∏£‡πâ‡∏≤‡∏á Title, Description, ‡πÅ‡∏•‡∏∞ Keywords ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠‡∏™‡∏±‡πâ‡∏ô (Short Video) ‡∏î‡πâ‡∏≤‡∏ô‡∏•‡πà‡∏≤‡∏á‡∏ô‡∏µ‡πâ:\n\n"
        f"‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠: {topic}\n"
        f"‡∏ä‡∏∑‡πà‡∏≠‡∏Ñ‡∏•‡∏¥‡∏õ: {title}\n"
        f"‡∏™‡∏Ñ‡∏£‡∏¥‡∏õ‡∏ï‡πå:\n{script}\n\n"
        "‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£:\n\n"
        "--- YouTube SEO ---\n\n"
        "‡∏ä‡∏∑‡πà‡∏≠‡∏Ñ‡∏•‡∏¥‡∏õ (Title): [‡∏ä‡∏∑‡πà‡∏≠‡∏Ñ‡∏•‡∏¥‡∏õ‡∏ó‡∏µ‡πà‡∏ô‡πà‡∏≤‡∏î‡∏∂‡∏á‡∏î‡∏π‡∏î‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠‡∏™‡∏±‡πâ‡∏ô, ‡πÑ‡∏°‡πà‡πÄ‡∏Å‡∏¥‡∏ô 60 ‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£, ‡πÅ‡∏•‡∏∞‡πÉ‡∏™‡πà Hashtags ‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á 3-5 ‡∏≠‡∏±‡∏ô]\n"
        "‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢ (Description): [‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏™‡∏±‡πâ‡∏ô‡πÜ ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö YouTube Shorts, ‡πÑ‡∏°‡πà‡πÄ‡∏Å‡∏¥‡∏ô 2-3 ‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ]\n\n"
        "--- Facebook / TikTok Caption ---\n\n"
        "Facebook Caption: [‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏±‡πâ‡∏ô‡∏î‡∏∂‡∏á‡∏î‡∏π‡∏î‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏ô‡πÉ‡∏à, ‡∏Å‡∏£‡∏∞‡∏ä‡∏±‡∏ö, ‡πÅ‡∏•‡∏∞‡πÉ‡∏™‡πà Hashtags ‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á 4-5 ‡∏≠‡∏±‡∏ô]\n\n"
        "TikTok Caption: [‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏±‡πâ‡∏ô‡∏î‡∏∂‡∏á‡∏î‡∏π‡∏î‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏ô‡πÉ‡∏à, ‡∏Å‡∏£‡∏∞‡∏ä‡∏±‡∏ö, ‡πÉ‡∏ä‡πâ Hashtags ‡∏¢‡∏≠‡∏î‡∏ô‡∏¥‡∏¢‡∏°‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á 4-5 ‡∏≠‡∏±‡∏ô]\n"
    )
    try:
        response = client.chat.completions.create(
            model="gpt-4o",
            messages=[{"role": "user", "content": prompt}],
            max_tokens=1000,
            temperature=0.7,
        )
        return response.choices[0].message.content.strip()
    except Exception as e:
        st.error(f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á SEO Content: {e}")
        return "‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á SEO Content"

# --- 6. CORE APPLICATION LOGIC (Audio Generation) ---
# --- 6. CORE APPLICATION LOGIC (Audio Generation) ---
def create_audio_from_script(gcp_client, script_text, voice_name):
    """
    ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏à‡∏≤‡∏Å‡∏™‡∏Ñ‡∏£‡∏¥‡∏õ‡∏ï‡πå (‡πÄ‡∏ß‡∏≠‡∏£‡πå‡∏ä‡∏±‡∏ô‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç: ‡πÉ‡∏ä‡πâ SSML ‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô)
    """
    if not gcp_client:
        st.error("Google TTS client ‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏ñ‡∏π‡∏Å‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á")
        return None

    clean_script = clean_script_for_tts(script_text)
    if not clean_script:
        st.warning("‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÑ‡∏î‡πâ‡∏´‡∏•‡∏±‡∏á‡∏à‡∏≤‡∏Å‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡∏™‡∏Ñ‡∏£‡∏¥‡∏õ‡∏ï‡πå")
        return None
    
    text_chunks = split_text_for_tts(clean_script)
    if not text_chunks:
        st.warning("‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÅ‡∏ö‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏õ‡πá‡∏ô‡∏™‡πà‡∏ß‡∏ô‡πÜ ‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°‡πÑ‡∏î‡πâ")
        return None
        
    audio_chunks = []
    progress_bar = st.progress(0, text="‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏™‡∏µ‡∏¢‡∏á...")

    # --- ‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç ---
    # 1. ‡∏™‡∏£‡πâ‡∏≤‡∏á Dictionary ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ñ‡∏≥‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏Å‡∏≤‡∏£‡∏≠‡∏≠‡∏Å‡πÄ‡∏™‡∏µ‡∏¢‡∏á
    # ‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡∏á‡πà‡∏≤‡∏¢‡∏ï‡πà‡∏≠‡∏Å‡∏≤‡∏£‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ñ‡∏≥‡∏≠‡∏∑‡πà‡∏ô‡πÜ ‡πÉ‡∏ô‡∏≠‡∏ô‡∏≤‡∏Ñ‡∏ï
    pronunciation_fixes = {
        "‡∏´‡∏•‡∏≠‡∏ô": "‡∏•‡πã‡∏≠‡∏ô"
        # ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ñ‡∏≥‡∏≠‡∏∑‡πà‡∏ô‡πÜ ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡πÑ‡∏î‡πâ‡∏ó‡∏µ‡πà‡∏ô‡∏µ‡πà ‡πÄ‡∏ä‡πà‡∏ô "‡∏≠‡∏ô‡∏∏‡∏ç‡∏≤‡∏ï": "‡∏≠‡∏∞‡∏ô‡∏∏‡∏¢‡∏≤‡∏î"
    }
    # --------------------

    for i, chunk in enumerate(text_chunks):
        try:
            # --- ‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç: ‡πÄ‡∏û‡∏¥‡πà‡∏° Logic ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Å‡πà‡∏≠‡∏ô‡∏™‡πà‡∏á ---
            use_ssml = False
            processed_text = chunk

            # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏°‡∏µ‡∏Ñ‡∏≥‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡πÉ‡∏ô chunk ‡∏ô‡∏µ‡πâ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
            for word, alias in pronunciation_fixes.items():
                if word in processed_text:
                    processed_text = processed_text.replace(word, f'<sub alias="{alias}">{word}</sub>')
                    use_ssml = True # ‡∏ñ‡πâ‡∏≤‡πÄ‡∏à‡∏≠ ‡πÉ‡∏´‡πâ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô True

            # ‡∏ñ‡πâ‡∏≤‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ä‡πâ SSML (‡πÄ‡∏û‡∏£‡∏≤‡∏∞‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡πÅ‡∏ó‡∏ô‡∏ó‡∏µ‡πà‡∏Ñ‡∏≥)
            if use_ssml:
                ssml_payload = f"<speak>{processed_text}</speak>"
                synthesis_input = texttospeech.SynthesisInput(ssml=ssml_payload)
                debug_info = ssml_payload
            # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ä‡πâ SSML (‡πÄ‡∏õ‡πá‡∏ô‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ‡∏õ‡∏Å‡∏ï‡∏¥)
            else:
                synthesis_input = texttospeech.SynthesisInput(text=chunk)
                debug_info = chunk
            # ----------------------------------------------------

            voice = texttospeech.VoiceSelectionParams(language_code="th-TH", name=voice_name)
            audio_config = texttospeech.AudioConfig(audio_encoding=texttospeech.AudioEncoding.MP3)
            
            response = gcp_client.synthesize_speech(
                input=synthesis_input, voice=voice, audio_config=audio_config
            )
            audio_chunks.append(response.audio_content)
            progress_bar.progress((i + 1) / len(text_chunks), text=f"‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà {i+1}/{len(text_chunks)}")

        except Exception as e:
            st.error(f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà {i+1}: {e}")
            st.info("‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÉ‡∏ô‡∏™‡πà‡∏ß‡∏ô (chunk) ‡∏ó‡∏µ‡πà‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î:")
            st.code(debug_info, language='text') # ‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏™‡πà‡∏á‡πÑ‡∏õ‡∏ï‡∏≠‡∏ô‡πÄ‡∏Å‡∏¥‡∏î‡∏õ‡∏±‡∏ç‡∏´‡∏≤
            progress_bar.empty()
            return None

    progress_bar.empty()

    if not audio_chunks:
        return None

    # ‡∏Å‡∏≤‡∏£‡∏£‡∏ß‡∏°‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏¢‡∏±‡∏á‡∏Ñ‡∏á‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡πÄ‡∏î‡∏¥‡∏°
    if len(audio_chunks) == 1:
        return audio_chunks[0]
    else:
        try:
            with st.spinner("‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏£‡∏ß‡∏°‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏™‡∏µ‡∏¢‡∏á..."):
                final_audio = AudioSegment.empty()
                for mp3_bytes in audio_chunks:
                    segment = AudioSegment.from_file(io.BytesIO(mp3_bytes), format="mp3")
                    final_audio += segment
                
                output_buffer = io.BytesIO()
                final_audio.export(output_buffer, format="mp3")
                return output_buffer.getvalue()
        except Exception as e:
            st.error(f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏£‡∏ß‡∏°‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏™‡∏µ‡∏¢‡∏á: {e}. ‡πÇ‡∏õ‡∏£‡∏î‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏Ñ‡∏∏‡∏ì‡πÑ‡∏î‡πâ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á ffmpeg ‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢‡πÅ‡∏•‡πâ‡∏ß")
            return None

# --- 7. STREAMLIT UI COMPONENTS ---
def render_left_column(openai_client):
    """‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏• UI ‡πÉ‡∏ô‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏î‡πâ‡∏≤‡∏ô‡∏ã‡πâ‡∏≤‡∏¢ (‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà 1 ‡πÅ‡∏•‡∏∞ 2)"""
    st.subheader("‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà 1: ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠‡πÅ‡∏•‡∏∞‡πÑ‡∏≠‡πÄ‡∏î‡∏µ‡∏¢")
    topic_options = ["‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏ú‡∏µ‡πÑ‡∏ó‡∏¢ & ‡∏ï‡∏≥‡∏ô‡∏≤‡∏ô‡∏•‡∏µ‡πâ‡∏•‡∏±‡∏ö", "‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå", "‡∏ß‡∏¥‡∏ó‡∏¢‡∏≤‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå‡∏£‡∏≠‡∏ö‡∏ï‡∏±‡∏ß", "‡∏Å‡∏≤‡∏£‡∏û‡∏±‡∏í‡∏ô‡∏≤‡∏ï‡∏ô‡πÄ‡∏≠‡∏á", "‡πÄ‡∏ó‡∏Ñ‡πÇ‡∏ô‡πÇ‡∏•‡∏¢‡∏µ AI", "‡∏Å‡∏≤‡∏£‡πÄ‡∏á‡∏¥‡∏ô-‡∏Å‡∏≤‡∏£‡∏•‡∏á‡∏ó‡∏∏‡∏ô", "‡∏™‡∏∏‡∏Ç‡∏†‡∏≤‡∏û & ‡πÑ‡∏•‡∏ü‡πå‡∏™‡πÑ‡∏ï‡∏•‡πå", "‡∏ó‡πà‡∏≠‡∏á‡πÄ‡∏ó‡∏µ‡πà‡∏¢‡∏ß & ‡∏õ‡∏£‡∏∞‡∏™‡∏ö‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏ä‡∏µ‡∏ß‡∏¥‡∏ï", "‡∏ö‡∏±‡∏ô‡πÄ‡∏ó‡∏¥‡∏á-‡∏ã‡∏µ‡∏£‡∏µ‡∏™‡πå/‡∏î‡∏≤‡∏£‡∏≤", "‡∏Ç‡πà‡∏≤‡∏ß/‡πÇ‡∏ã‡πÄ‡∏ä‡∏µ‡∏¢‡∏•/‡πÄ‡∏ó‡∏£‡∏ô‡∏î‡πå‡∏Æ‡∏¥‡∏ï", "How-To / ‡πÄ‡∏Ñ‡∏•‡πá‡∏î‡∏•‡∏±‡∏ö / DIY", "‡∏ò‡∏£‡∏£‡∏°‡∏ä‡∏≤‡∏ï‡∏¥/‡∏™‡∏±‡∏ï‡∏ß‡πå‡πÇ‡∏•‡∏Å", "‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠ (‡∏Ñ‡∏¥‡∏î‡πÄ‡∏≠‡∏á)"]
    topic = st.selectbox("‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà‡∏´‡∏•‡∏±‡∏Å", topic_options, key="topic_select")
    
    custom_topic = ""
    if topic == "‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠ (‡∏Ñ‡∏¥‡∏î‡πÄ‡∏≠‡∏á)":
        custom_topic = st.text_input("‡∏û‡∏¥‡∏°‡∏û‡πå‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠‡∏ó‡∏µ‡πà‡∏Ñ‡∏∏‡∏ì‡∏™‡∏ô‡πÉ‡∏à:", placeholder="‡πÄ‡∏ä‡πà‡∏ô '‡∏õ‡∏£‡∏≤‡∏Å‡∏è‡∏Å‡∏≤‡∏£‡∏ì‡πå‡πÄ‡∏î‡∏à‡∏≤‡∏ß‡∏π'", key="custom_topic_input")
    
    st.session_state.topic_final = custom_topic if topic == "‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠ (‡∏Ñ‡∏¥‡∏î‡πÄ‡∏≠‡∏á)" and custom_topic else topic

    if st.button("üß† ‡∏™‡∏∏‡πà‡∏° 5 ‡πÑ‡∏≠‡πÄ‡∏î‡∏µ‡∏¢‡∏à‡∏≤‡∏Å‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠‡∏ô‡∏µ‡πâ", use_container_width=True):
        if not st.session_state.topic_final:
            st.warning("‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏´‡∏£‡∏∑‡∏≠‡∏û‡∏¥‡∏°‡∏û‡πå‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠‡∏Å‡πà‡∏≠‡∏ô")
        else:
            with st.spinner("‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏£‡∏∞‡∏î‡∏°‡∏™‡∏°‡∏≠‡∏á..."):
                if st.session_state.get("openai_client"):
                    st.session_state.idea_list = gen_idea_list(st.session_state.openai_client, st.session_state.topic_final)
                    st.session_state.selected_idea = ""
                    st.session_state.script = None
                    st.session_state.audio_bytes = None
                else:
                    st.error("OpenAI client ‡πÑ‡∏°‡πà‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤")

    if 'idea_list' in st.session_state and st.session_state.idea_list:
        st.session_state.selected_idea = st.radio(
            "‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÑ‡∏≠‡πÄ‡∏î‡∏µ‡∏¢‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£:",
            st.session_state.idea_list,
            index=None,
            key="idea_radio"
        )

    st.subheader("‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà 2: ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏™‡∏Ñ‡∏£‡∏¥‡∏õ‡∏ï‡πå")
    length_options = {"30 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ (‡∏™‡∏±‡πâ‡∏ô)": 30, "60 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ (‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô)": 60, "90 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ (‡∏¢‡∏≤‡∏ß)": 90}
    length_choice = st.selectbox(
        "‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠‡πÇ‡∏î‡∏¢‡∏õ‡∏£‡∏∞‡∏°‡∏≤‡∏ì",
        length_options.keys(),
        key="length_select"
    )
    
    script_gen_disabled = not st.session_state.get("selected_idea")
    if st.button("‚úçÔ∏è ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏™‡∏Ñ‡∏£‡∏¥‡∏õ‡∏ï‡πå‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠", type="primary", use_container_width=True, disabled=script_gen_disabled):
        with st.spinner("‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡∏™‡∏Ñ‡∏£‡∏¥‡∏õ‡∏ï‡πå... ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏£‡∏≠‡∏™‡∏±‡∏Å‡∏Ñ‡∏£‡∏π‡πà"):
            if st.session_state.get("openai_client"):
                script = gen_script(
                    st.session_state.openai_client,
                    st.session_state.topic_final,
                    st.session_state.selected_idea,
                    length_options[length_choice]
                )
                st.session_state.script = script
                st.session_state.audio_bytes = None
            else:
                st.error("OpenAI client ‡πÑ‡∏°‡πà‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤")

def render_right_column(gcp_tts_client):
    """‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏• UI ‡πÉ‡∏ô‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏î‡πâ‡∏≤‡∏ô‡∏Ç‡∏ß‡∏≤ (‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà 3)"""
    st.subheader("üìù ‡∏™‡∏Ñ‡∏£‡∏¥‡∏õ‡∏ï‡πå‡πÅ‡∏•‡∏∞‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏û‡∏≤‡∏Å‡∏¢‡πå")

    if 'script' not in st.session_state or not st.session_state.script:
        st.info("‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏Ç‡∏≠‡∏á‡∏™‡∏Ñ‡∏£‡∏¥‡∏õ‡∏ï‡πå‡πÅ‡∏•‡∏∞‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏û‡∏≤‡∏Å‡∏¢‡πå‡∏à‡∏∞‡πÅ‡∏™‡∏î‡∏á‡∏ó‡∏µ‡πà‡∏ô‡∏µ‡πà")
        return

    st.success("‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏™‡∏Ñ‡∏£‡∏¥‡∏õ‡∏ï‡πå‡πÄ‡∏™‡∏£‡πá‡∏à‡πÅ‡∏•‡πâ‡∏ß! ‡∏Ñ‡∏∏‡∏ì‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏î‡πâ‡∏≤‡∏ô‡∏•‡πà‡∏≤‡∏á‡πÑ‡∏î‡πâ")
    
    edited_script = st.text_area(
        "‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏™‡∏Ñ‡∏£‡∏¥‡∏õ‡∏ï‡πå:",
        value=st.session_state.script,
        height=300,
        key="script_editor"
    )
    st.session_state.script = edited_script # Update script in session state

    st.markdown("---")
    st.subheader("‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà 3: ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏û‡∏≤‡∏Å‡∏¢‡πå")

    voice_friendly_names = [v[0] for v in VOICE_LIST]
    selected_voice_friendly_name = st.selectbox("‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏û‡∏≤‡∏Å‡∏¢‡πå:", voice_friendly_names, key="voice_select")
    selected_voice_name = next(v[1] for v in VOICE_LIST if v[0] == selected_voice_friendly_name)

    if st.button("üîä ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÅ‡∏•‡∏∞‡∏ü‡∏±‡∏á‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏û‡∏≤‡∏Å‡∏¢‡πå", use_container_width=True):
        st.session_state.audio_bytes = None
        if st.session_state.get("gcp_tts_client"):
            audio_data = create_audio_from_script(st.session_state.gcp_tts_client, edited_script, selected_voice_name)
            if audio_data:
                st.session_state.audio_bytes = audio_data

                idea_name = st.session_state.get("selected_idea", "voice")
                safe_idea = re.sub(r'[^A-Za-z0-9‡∏Å-‡πô_]+', '_', idea_name.strip())[:40]

                output_dir = os.path.join(os.getcwd(), "outputmp3")
                os.makedirs(output_dir, exist_ok=True)
                output_path = os.path.join(output_dir, f"{safe_idea}.mp3")

                with open(output_path, "wb") as f:
                    f.write(audio_data)

                st.info(f"üíæ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÑ‡∏ß‡πâ‡∏ó‡∏µ‡πà: `{output_path}`")
        else:
            st.error("Google TTS client ‡πÑ‡∏°‡πà‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤")

    if 'audio_bytes' in st.session_state and st.session_state.audio_bytes:
        st.audio(st.session_state.audio_bytes, format="audio/mp3")
        style_desc = get_voice_style_by_topic(st.session_state.topic_final)
        st.markdown(f"**‡∏™‡πÑ‡∏ï‡∏•‡πå‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏ó‡∏µ‡πà‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠‡∏ô‡∏µ‡πâ:** `{style_desc}`")

    st.markdown("---")
    st.subheader("‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà 4: ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠")
    
    video_gen_disabled = ('script' not in st.session_state or not st.session_state.script or
                          'audio_bytes' not in st.session_state or not st.session_state.audio_bytes)

    if st.button("üé¨ ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠", type="primary", use_container_width=True, disabled=video_gen_disabled):
        if not st.session_state.get("selected_idea"):
            st.warning("‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÑ‡∏≠‡πÄ‡∏î‡∏µ‡∏¢‡∏Å‡πà‡∏≠‡∏ô‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠")
            return

        with st.spinner("‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠... ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ô‡∏µ‡πâ‡∏≠‡∏≤‡∏à‡πÉ‡∏ä‡πâ‡πÄ‡∏ß‡∏•‡∏≤‡∏´‡∏•‡∏≤‡∏¢‡∏ô‡∏≤‡∏ó‡∏µ"): 
            if not st.session_state.get("openai_client"):
                st.error("OpenAI client ‡πÑ‡∏°‡πà‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤")
                return
            if not st.session_state.get("audio_bytes"):
                st.error("‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏™‡∏µ‡∏¢‡∏á ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏û‡∏≤‡∏Å‡∏¢‡πå‡∏Å‡πà‡∏≠‡∏ô")
                return
            if not st.session_state.get("script"):
                st.error("‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏™‡∏Ñ‡∏£‡∏¥‡∏õ‡∏ï‡πå ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏™‡∏Ñ‡∏£‡∏¥‡∏õ‡∏ï‡πå‡∏Å‡πà‡∏≠‡∏ô")
                return

            try:
                audio_temp_path = os.path.join(os.getcwd(), "temp_audio.mp3")
                with open(audio_temp_path, "wb") as f:
                    f.write(st.session_state.audio_bytes)

                final_video_path = generate_final_video(
                    script_text=st.session_state.script,
                    voice_path=audio_temp_path,
                    topic=st.session_state.topic_final,
                    openai_client=st.session_state.openai_client,    
                    video_title=st.session_state.selected_idea,
                )
                if final_video_path:
                    st.success("‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå!")
                    st.session_state.final_video_path = final_video_path   # <<<<<< ‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç
                else:
                    st.error("‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠‡πÑ‡∏î‡πâ. ‡πÇ‡∏õ‡∏£‡∏î‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡∏î‡πâ‡∏≤‡∏ô‡∏ö‡∏ô.")
            except Exception as e:
                st.error(f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠: {e}")
            finally:
                if os.path.exists(audio_temp_path):
                    os.remove(audio_temp_path)

    # <<<< ‡πÉ‡∏™‡πà‡∏ï‡∏£‡∏á‡∏ô‡∏µ‡πâ! ‡πÑ‡∏°‡πà‡∏ß‡πà‡∏≤ user ‡∏à‡∏∞‡∏Å‡∏î‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡∏Å‡∏µ‡πà‡∏£‡∏≠‡∏ö ‡∏õ‡∏∏‡πà‡∏°‡∏Å‡∏±‡∏ö preview ‡∏Å‡πá‡∏¢‡∏±‡∏á‡∏≠‡∏¢‡∏π‡πà
    if 'final_video_path' in st.session_state and os.path.exists(st.session_state['final_video_path']):
        st.video(st.session_state['final_video_path'])
        st.download_button(
            label="‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠",
            data=open(st.session_state['final_video_path'], "rb").read(),
            file_name=os.path.basename(st.session_state['final_video_path']),
            mime="video/mp4",
            use_container_width=True
        )

    # --- NEW: Step 5 - SEO Content Generation ---
    st.markdown("---")
    st.subheader("‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà 5: ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÅ‡∏Ñ‡∏õ‡∏ä‡∏±‡πà‡∏ô‡πÅ‡∏•‡∏∞ SEO")

    seo_gen_disabled = not (st.session_state.get("script") and st.session_state.get("selected_idea") and st.session_state.get("topic_final"))

    if st.button("‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÅ‡∏Ñ‡∏õ‡∏ä‡∏±‡πà‡∏ô‡πÇ‡∏û‡∏™ (YouTube/Facebook/TikTok)", key="seo_button", disabled=seo_gen_disabled, type="secondary", use_container_width=True):
        with st.spinner("‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÅ‡∏Ñ‡∏õ‡∏ä‡∏±‡πà‡∏ô‡πÅ‡∏•‡∏∞ SEO..."):
            if st.session_state.get("openai_client"):
                seo_content = generate_seo_content(
                    st.session_state.openai_client,
                    st.session_state.topic_final,
                    st.session_state.selected_idea,
                    st.session_state.script
                )
                st.session_state.seo_output = seo_content
            else:
                st.error("OpenAI client ‡πÑ‡∏°‡πà‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô")

    if 'seo_output' in st.session_state and st.session_state.seo_output:
        st.markdown("### üìù ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå SEO ‡πÅ‡∏•‡∏∞‡πÅ‡∏Ñ‡∏õ‡∏ä‡∏±‡πà‡∏ô")
        st.markdown(st.session_state.seo_output)


# --- 8. MAIN APPLICATION ENTRY POINT ---
def main():
    st.title("WAWATUBE-DEMO")
    st.caption("‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏°‡∏∑‡∏≠‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ñ‡∏≠‡∏ô‡πÄ‡∏ó‡∏ô‡∏ï‡πå‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠‡∏Ñ‡∏£‡∏ö‡∏ß‡∏á‡∏à‡∏£ ‡∏ï‡∏±‡πâ‡∏á‡πÅ‡∏ï‡πà‡∏Ñ‡∏¥‡∏î‡πÑ‡∏≠‡πÄ‡∏î‡∏µ‡∏¢ ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡∏™‡∏Ñ‡∏£‡∏¥‡∏õ‡∏ï‡πå ‡∏à‡∏ô‡∏ñ‡∏∂‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏û‡∏≤‡∏Å‡∏¢‡πå")
    
    # --- ‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÇ‡∏Ñ‡πâ‡∏î‡∏™‡πà‡∏ß‡∏ô‡∏ô‡∏µ‡πâ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡∏£‡∏±‡∏ö‡∏Ç‡∏ô‡∏≤‡∏î‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠ ---
    st.markdown("""
    <style>
    video {
        max-width: 30%; /* ‡∏õ‡∏£‡∏±‡∏ö‡∏Ç‡∏ô‡∏≤‡∏î‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÉ‡∏´‡πâ‡πÄ‡∏•‡πá‡∏Å‡∏•‡∏á */
        margin: auto;     /* ‡∏à‡∏±‡∏î‡πÉ‡∏´‡πâ‡∏≠‡∏¢‡∏π‡πà‡∏ï‡∏£‡∏á‡∏Å‡∏•‡∏≤‡∏á */
    }
    </style>
    """, unsafe_allow_html=True)
    # ----------------------------------------

    if 'openai_client' not in st.session_state:
        initialize_clients() # This populates session_state.openai_client and session_state.gcp_tts_client

    openai_client = st.session_state.get("openai_client")
    gcp_tts_client = st.session_state.get("gcp_tts_client")

    if openai_client is None or gcp_tts_client is None:
        st.warning("‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ API Keys ‡πÉ‡∏ô‡πÑ‡∏ü‡∏•‡πå .env ‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏≠‡∏¥‡∏ô‡πÄ‡∏ó‡∏≠‡∏£‡πå‡πÄ‡∏ô‡πá‡∏ï")
        # st.stop() # Removed stop() to allow initialization error messages to be displayed

    col1, col2 = st.columns([1, 1])

    with col1:
        render_left_column(openai_client)

    with col2:
        render_right_column(gcp_tts_client)


if __name__ == "__main__":
    main()
